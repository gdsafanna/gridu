{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import Ridge,Lasso, LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import grid_search\n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import pipeline, grid_search\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading train and test data and merging it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['product_uid', 'product_title', 'search_term', 'relevance'], dtype='object')\n",
      "Index(['product_uid', 'product_title', 'search_term'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('./Home Depot Product Search Relevance/train.csv', index_col=0, header=0,encoding=\"ISO-8859-1\")\n",
    "test=pd.read_csv('./Home Depot Product Search Relevance/test.csv', index_col=0, header=0,encoding=\"ISO-8859-1\")\n",
    "print(train.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat((train, test), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spellchecker(word):\n",
    "    if isinstance(word, str):\n",
    "        word = word.replace(\"toliet\",\"toilet\")\n",
    "        word = word.replace(\"airconditioner\",\"air condition\")\n",
    "        word = word.replace(\"vinal\",\"vinyl\")\n",
    "        word = word.replace(\"vynal\",\"vinyl\")\n",
    "        word = word.replace(\"skill\",\"skil\")\n",
    "        word = word.replace(\"snowbl\",\"snow bl\")\n",
    "        word = word.replace(\"plexigla\",\"plexi gla\")\n",
    "        word = word.replace(\"rustoleum\",\"rust oleum\")\n",
    "        word = word.replace(\"whirpool\",\"whirlpool\")\n",
    "        word = word.replace(\"whirlpoolga\", \"whirlpool ga\")\n",
    "        word = word.replace(\"whirlpoolstainless\",\"whirlpool stainless\")\n",
    "        word = word.replace(\"cablrail\",\"CableRail\")\n",
    "        word = word.replace(\"whellbarrow\",\"wheelbarrow\")\n",
    "        word = word.replace(\"kolher\",\"kohler\")\n",
    "        word = word.replace(\"rustolem\",\"rust oleum\")\n",
    "        word = word.replace(\"hagchet\",\"hatchet\")\n",
    "        word = word.replace(\"fridgedaire\",\"frigidaire\")\n",
    "        word = word.replace(\"doorbell\",\"door bell\")\n",
    "        word = word.replace(\"traficmaster\",\"trafficmaster\")\n",
    "        word = word.replace(\"freesstanding\",\"freestanding\")\n",
    "        word = word.replace(\"versatiube\",\"versatube\")\n",
    "        word = word.replace(\"walmound\",\"wall mount\")\n",
    "        word = word.replace(\"makersbot\",\"maker bot\")\n",
    "        word = word.replace(\"pfistersaxton\",\"pfister saxton\")\n",
    "        word = word.replace(\"flotex\",\"flotec\")\n",
    "        word = word.replace(\"windowbalance\",\"window balance\")\n",
    "        word = word.replace(\"meu\",\"med\")\n",
    "        word = word.replace(\"loadspeaker\",\"loudspeaker\")\n",
    "        word = word.replace(\"tapecase\",\"tape case\")\n",
    "        word = word.replace(\"spgot\",\"spigot\")\n",
    "        word = word.replace(\"whitesilicone\",\"white silicone\")\n",
    "        word = word.replace(\"bracket\",\"angle\")\n",
    "        word = word.replace(\"simpon\",\"simpson\")\n",
    "        word = word.replace(\"papertowels\",\"paper towels\")\n",
    "        word = word.replace(\"organozers\",\"organizer\")\n",
    "        word = word.replace(\"miraposa\",\"mariposa\")\n",
    "        if word==\"deck over\":\n",
    "            word = \"deckover\"\n",
    "    word=re.sub('[,.;:\"!@#$-]', ' ', word).strip().lower()\n",
    "    return word\n",
    "data['search_term']=data['search_term'].map(lambda x: spellchecker(x))\n",
    "data['product_title']=data['product_title'].map(lambda x: spellchecker(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>relevance</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>simpson strong tie 12 gauge angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>angle angle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simpson strong tie 12 gauge angle</td>\n",
       "      <td>100001</td>\n",
       "      <td>2.50</td>\n",
       "      <td>l angle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>behr premium textured deckover 1 gal  sc 141 t...</td>\n",
       "      <td>100002</td>\n",
       "      <td>3.00</td>\n",
       "      <td>deckover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delta vero 1 handle shower only faucet trim ki...</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.33</td>\n",
       "      <td>rain shower head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>delta vero 1 handle shower only faucet trim ki...</td>\n",
       "      <td>100005</td>\n",
       "      <td>2.67</td>\n",
       "      <td>shower only faucet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       product_title  product_uid  relevance  \\\n",
       "0                  simpson strong tie 12 gauge angle       100001       3.00   \n",
       "1                  simpson strong tie 12 gauge angle       100001       2.50   \n",
       "2  behr premium textured deckover 1 gal  sc 141 t...       100002       3.00   \n",
       "3  delta vero 1 handle shower only faucet trim ki...       100005       2.33   \n",
       "4  delta vero 1 handle shower only faucet trim ki...       100005       2.67   \n",
       "\n",
       "          search_term  \n",
       "0         angle angle  \n",
       "1             l angle  \n",
       "2            deckover  \n",
       "3    rain shower head  \n",
       "4  shower only faucet  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading attributes information. I am going to use brand and material information from that (according to instructions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attributes=pd.read_csv('./Home Depot Product Search Relevance/attributes.csv',header=0, dtype=str)\n",
    "attributes.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 21s, sys: 3.64 s, total: 6min 24s\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "brand=attributes[['product_uid','value']][attributes.name=='MFG Brand Name']\n",
    "brand.columns=['product_uid','brand']\n",
    "brand['brand']=brand.brand.apply(lambda x: x.lower())\n",
    "material=attributes[['product_uid','value']][attributes.name.str.contains(\"Material\")]\n",
    "dframe=pd.DataFrame(columns=['product_uid','material'])\n",
    "product_uid=[]\n",
    "material_lst=[]\n",
    "for u in material.product_uid.unique():\n",
    "    lst=\"\"\n",
    "    m=material[material.product_uid==u]\n",
    "    for v in m.value.unique():\n",
    "        lst=lst+v.lower()\n",
    "    product_uid.append(u)\n",
    "    material_lst.append(lst)\n",
    "dframe['product_uid']=product_uid\n",
    "dframe['material']=material_lst\n",
    "dframe['material']=dframe.material.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 23min 24s, sys: 16 s, total: 1h 23min 40s\n",
      "Wall time: 1h 24min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "functionality=attributes[['product_uid','value']][attributes.name.str.contains(\"Bullet\")]\n",
    "func_frame=pd.DataFrame(columns=['product_uid','functionality'])\n",
    "product_uid=[]\n",
    "func_lst=[]\n",
    "for u in functionality.product_uid.unique():\n",
    "    lst=\"\"\n",
    "    f=functionality[functionality.product_uid==u]\n",
    "    for v in f.value.unique():\n",
    "        lst=lst+re.sub('[,.;:\"!@#$-]', ' ', v).strip().lower()\n",
    "    product_uid.append(u)\n",
    "    func_lst.append(lst)\n",
    "func_frame['product_uid']=product_uid\n",
    "func_frame['functionality']=func_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading product description information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proddescription=pd.read_csv('./Home Depot Product Search Relevance/product_descriptions.csv',header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all data (train-test set, attributes and product description information):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data= pd.merge(data, proddescription, how='left', on='product_uid')\n",
    "dframe['product_uid']=dframe.product_uid.astype(int)\n",
    "data= pd.merge(data, dframe, how='left', on='product_uid')\n",
    "brand['product_uid']=brand.product_uid.astype(int)\n",
    "data= pd.merge(data, brand, how='left', on='product_uid')\n",
    "func_frame['product_uid']=func_frame.product_uid.astype(int)\n",
    "data= pd.merge(data, func_frame, how='left', on='product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[['material','brand','functionality']]=data[['material','brand','functionality']].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['product_title']=data.product_title.apply(lambda x: re.sub('[,.;:\"!@#$-]', ' ', x).strip().lower())\n",
    "data['search_term']=data.search_term.apply(lambda x: re.sub('[,.;:\"!@#$-]', ' ', x).strip().lower())\n",
    "data['product_description']=data.product_description.apply(lambda x: re.sub('[,.;:\"!@#$-]', ' ', x).strip().lower())\n",
    "data['brand']=data.brand.apply(lambda x: re.sub('[,.;:\"!@#$-]', ' ', x).strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I am going to stem words in product_title, search_term, product_description, material, brand and functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_word(x,d=1):\n",
    "    if d==1:\n",
    "        stop_words = ['for', 'and', 'in', 'on','with','what','from','that','less']\n",
    "    else:\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "    for word in x.split(\" \"):\n",
    "        if word in stop_words:\n",
    "            x.replace(word,\"\")\n",
    "    return x\n",
    "data['search_term']=data['search_term'].apply(lambda x: stop_word(x,1))\n",
    "data['product_description']=data['product_description'].apply(lambda x: stop_word(x,2))\n",
    "data['functionality']=data['functionality'].apply(lambda x: stop_word(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 2s, sys: 3.35 s, total: 19min 6s\n",
      "Wall time: 19min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stem=nltk.stem.PorterStemmer()\n",
    "def stemmer(x):\n",
    "    if len(x)>0:\n",
    "        x = (\" \").join([stem.stem(str(z)) for z in x.split(\" \")])\n",
    "        return x\n",
    "    else:\n",
    "        return 'null'\n",
    "for col in ['product_title','search_term','product_description','material','brand','functionality']:\n",
    "    data[col]=data[col].apply(lambda x: stemmer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create variables: quantity of word which are in search_term and in product_title, product_description, material, brand, functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=['len_st']\n",
    "for col in ['product_title','product_description','material','brand','functionality']:\n",
    "    data['st_in_'+col]=data[['search_term', col]].apply(lambda x: len([w for w in x[0].split(\" \") if w in x[1].split(\" \")]), axis=1)\n",
    "    #data['rat_'+col]=data[['search_term', col]].apply(lambda x: len([w for w in x[0].split(\" \") if w in x[1].split(\" \")])/len(x[0].split(\" \")), axis=1)\n",
    "    data['len_'+col]=data[col].apply(lambda x: len(x.split(\" \")))\n",
    "    variables.append('st_in_'+col)\n",
    "    variables.append('rat_'+col)\n",
    "    variables.append('len_'+col)\n",
    "data['len_st']=data.search_term.apply(lambda x: len(x.split(\" \")))\n",
    "data['st_in_brand']=data['st_in_brand'].apply(lambda x:2*x)\n",
    "data['st_in_functionality']=data['st_in_functionality'].apply(lambda x:2*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lentr=train.shape[0]\n",
    "data_train=data[:lentr]\n",
    "data_test=data[lentr:]\n",
    "Y_train=data_train['relevance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_score', 'colsample_bylevel', 'colsample_bytree', 'gamma', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_estimators', 'nthread', 'objective', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'seed', 'silent', 'subsample'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=data_train[variables]\n",
    "X_test=data_test[variables]\n",
    "estimator=XGBRegressor(seed=0)\n",
    "#estimator1 = RandomForestRegressor(random_state = 0, n_jobs=-1, verbose=1)\n",
    "#estimator=BaggingRegressor(estimator1,random_state=0,n_estimators=15)\n",
    "estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.23531153820586398\n",
      "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
      "       min_child_weight=1, missing=None, n_estimators=95, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "params_grid = {\n",
    "    'max_depth':[4,5,6],\n",
    "    'n_estimators' : [75,80,85,90,95]\n",
    "}\n",
    "grid = grid_search.GridSearchCV(estimator, params_grid, scoring = 'neg_mean_squared_error', cv = 5)\n",
    "grid.fit(X=X_train,y=Y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator=grid.best_estimator_\n",
    "y_test=estimator.predict(X_test)\n",
    "test['pred']=np.round(y_test,2)\n",
    "test['pred'].to_csv('submision.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Final score 0.48685"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
